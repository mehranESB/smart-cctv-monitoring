# ğŸ¥ Deep Learning-Powered CCTV Data Processing and Analysis 

## ğŸ“ Overview

This project provides a flexible and scalable framework to **process, analyze, and visualize CCTV camera data using deep learning models**.<br>
It is designed to handle multiple cameras across different floors, perform real-time computer vision tasks like **person detection, multi-camera tracking**, and **birdâ€™s-eye view transformations**, and make the processed information available for **monitoring, alerts**, analytics, or any **custom purpose**.<br>
The system is modular and expandable â€” allowing easy development for various applications such as population analysis, event detection, visual reporting, or security monitoring.

## ğŸ§© System Architecture

The overall data flow of the system:
1. **Data Ingestion:**
CCTV streams from multiple cameras (across different floors) are collected through a Camera Hub.
2. **Storage Server:**
Raw or preprocessed camera data is optionally saved for further offline processing.
3. **Processing Manager:**
A central manager leverages deep neural networks and device resources (e.g., GPUs, edge devices) to run heavy computer vision tasks.
4. **Results Management:**
Outputs are saved back to the storage server and forwarded to the Monitoring System for visualization and operational use.

<div style="text-align: center;">
  <img src="./images/dataflow.png" style="max-width: 500px; width: 100%; height: auto; padding: 50px;" alt="system data flow">
</div>

## âš™ï¸ Features
- ğŸš€ Scalable multi-camera data ingestion

- ğŸ§  Deep Learning-based object detection and tracking

- ğŸ—ºï¸ Bird's-eye view floor visualization

- ğŸ› ï¸ Flexible framework for custom purposes (counting, alerting, analytics, etc.)

- ğŸ“Š Centralized storage and result management

- ğŸ–¥ï¸ Designed for real-time and offline analysis

## ğŸ¬ Visualization and Results

The system provides visual feedback including:
- Real-time detection results
- Birdâ€™s-eye view transformation across multiple cameras
- Tracking of individuals throughout different floor plans

<div style="text-align: center;">
  <img src="./images/runtime.gif" style="max-width: 500px; width: 100%; height: auto; padding: 50px;" alt="run time example">
</div>

## ğŸ› ï¸ Camera Calibration for Birdâ€™s-Eye View Transformation

To accurately transform each cameraâ€™s view into a birdâ€™s-eye (floor plan) perspective, an initial **calibration step** is required.<br>
We have designed an easy-to-use **GUI application built with `Tkinter`** to help users perform the calibration effortlessly.<br>
This calibration is done **only once per camera**, and the computed parameters are saved for future use.

Calibration involves these steps:

- **ğŸ¯ Select Region of Interest (ROI):**

  The user defines an area within the camera view that should appear in the birdâ€™s-eye visualization.

- **ğŸ§© Match Reference Points:**

  The user sets several corresponding points between the **camera view** and the **floor plan**. These points are used to compute a **homography transformation**.

- **ğŸ—ºï¸ Place Camera on Floor Plan:**

  The user positions the camera accurately on the floor plan to provide a correct spatial reference.

- **ğŸ’¾ Save Calibration Data:**

  All calibration details are saved into a structured **JSON file**, making it easy for the Camera Handler modules to read and use during live processing.

> ğŸï¸ Below you can see a GIF demonstrating the complete calibration process step-by-step.

<div style="text-align: center;">
  <img src="./images/app_steps.gif" style="max-width: 500px; width: 100%; height: auto; padding: 50px;" alt="run time example">
</div>

## ğŸ§  Extending Computer Vision Capabilities

In addition to standard object detection and person tracking, this framework is **designed for flexible expansion** by integrating additional deep learning models to extract richer analytics from CCTV streams.

We have already developed and integrated several extra models, including:

- **ğŸ‘¤ Face Detection:**

  Detect and locate faces in the camera feeds.

- **ğŸ•º Body Keypoint Detection:**

  Identify and track key points on the human body (e.g., head, shoulders, knees).

- **ğŸ¯ Action Detection:**

  Recognize human activities or specific motions within the monitored areas.

These new capabilities can be **plugged into the Manager module** to enhance analytics, but **note**:<br>
Adding these complex models increases **computational cost** and **processing time**, potentially impacting real-time performance.

> ğŸï¸ Below you can see a GIF demonstrating these extra computer vision features.

<div style="text-align: center;">
  <img src="./images//extend_features.gif" style="max-width: 500px; width: 100%; height: auto; padding: 50px;" alt="run time example">
</div>

## ğŸ”® Future Developments
We are actively working on adding even more advanced functionalities:

- **ğŸ†” Face Identification:**  

  Recognize and identify individuals based on their detected faces.

- **ğŸ”„ Person Re-Identification (Re-ID):**

  Track the same person across different cameras without relying solely on appearance in each frame.

- **ğŸ—„ï¸ Database Communication:**

  Save processed analytics data to a database and retrieve necessary information for advanced analysis and reporting.

These future features will make the system even more intelligent, scalable, and suitable for real-world surveillance and business intelligence applications.

## ğŸ“¢ Important Note

This repository has been created to **showcase the design, architecture, and results** of my work in applying deep learning to CCTV data analysis as a **computer vision** task.
Due to **institutional copyright policies**, the full project code cannot be shared publicly at this time.

Thank you for your interest and understanding.

